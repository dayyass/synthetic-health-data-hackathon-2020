{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alzheimer MRI images data notebook \n",
    "by Martin Closter Jespersen from Deloitte Consulting\n",
    "\n",
    "## About the data \n",
    "The data was generated from a real patient cohort of MRI images both with and without alzheimer. The real images are in the dimension of 128x128 and consists of the following distribution (i.e. real distribution):\n",
    "- 2560 Non alzheimer\n",
    "- 1792 Very mild alzheimer \n",
    "- 717  Mild alzheimer\n",
    "- 52   Moderate alzheimer\n",
    "\n",
    "You are provided an evenly distributed synthetic dataset of ~3000 128x128 synthetic MRI images of each class. \n",
    "\n",
    "The data was generated using a simple (non state-of-the-art) <b>Conditional Generative Adversial Network (cGAN)</b>. cGANs are generally data hungry and considering this small dataset with great class imbalance, the data quality can be <u><b>limited</b></u>. Though image applications of machine learning has developed far, creating diverse synthetic images is still the main bottleneck. More sophisticated methods have improved this substantially but was not used here due to time and dataset size.\n",
    "\n",
    "Reading material:\n",
    "* Analysis of using GANs to replace real biomedical images in classification https://arxiv.org/pdf/1904.08688.pdf\n",
    "* Synthetic COVID X ray images https://arxiv.org/pdf/2009.12478.pdf\n",
    "* Synthetizing chest X ray images for model development https://www.researchgate.net/publication/328945795_Synthesizing_Chest_X-Ray_Pathology_for_Training_Deep_Convolutional_Neural_Networks\n",
    "\n",
    "\n",
    "Investigate how the data can be useful!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible challenges\n",
    "- Can you train a model on synthetic data to predict alzheimers on real data (binary = No alzheimer or not)\n",
    "    - Easiest task of prediction\n",
    "    - Play with best distribution / synthetic data size needed (most likely a small subsample is sufficient). \n",
    "    - Removing redundancy (too similar images) might be needed  (https://github.com/JohannesBuchner/imagehash)\n",
    "    - Does the performance on real data increase if training only using synthetic data a subset of the alzheimer classes (i.e. leave out less frequent ones)?\n",
    "- How well does the synthetic data behave on each class on the real data?\n",
    "    - More complicated task of prediction\n",
    "- How does a model trained on the real data behave on the synthetic data?\n",
    "    - This can be useful if one wants to scale a model to new country and want to evaluate if it would succeed\n",
    "- Do the model trained on real and synthetic data behave similarly? \n",
    "    - I.e. do they predict same targets the same classes, or do they use the same part of the images to classify (Grad-CAM or similar method)\n",
    "- Can you improve the model trained on real data by augmenting it with synthetic data in the training?\n",
    "- Explore and compare the real and synthetic data\n",
    "    - Average pixel of each separate class or other create ideas?\n",
    "- Can you build a model which can predict real from synthetic images, and if so can you understand why it can differentiate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_images, set_global_seed\n",
    "from dataset import MRIDataset, Unsqueeze, Repeat\n",
    "from train import train, validate_epoch, metrics_callback\n",
    "from convnet import ConvDropoutNet, ConvBatchNormNet, make_resnet18, make_pretrained_resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading in the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [00:03<00:00, 3811.84it/s]\n",
      "100%|██████████| 5121/5121 [00:01<00:00, 3836.60it/s]\n",
      "100%|██████████| 1279/1279 [00:00<00:00, 3946.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "synth_images, synth_labels = load_images('data/SyntheticDataset', verbose=True)\n",
    "real_images, real_labels = load_images('data/RealDataset', verbose=True)\n",
    "real_final_images, real_final_labels = load_images('data/RealTestDataset', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synth_images shape: (12000, 128, 128)\n",
      "synth_labels shape: (12000,)\n",
      "\n",
      "real_images shape: (5121, 128, 128)\n",
      "real_labels shape: (5121,)\n",
      "\n",
      "real_final_images shape: (1279, 128, 128)\n",
      "real_final_labels shape: (1279,)\n"
     ]
    }
   ],
   "source": [
    "# print shapes\n",
    "print(f'synth_images shape: {synth_images.shape}')\n",
    "print(f'synth_labels shape: {synth_labels.shape}')\n",
    "print()\n",
    "print(f'real_images shape: {real_images.shape}')\n",
    "print(f'real_labels shape: {real_labels.shape}')\n",
    "print()\n",
    "print(f'real_final_images shape: {real_final_images.shape}')\n",
    "print(f'real_final_labels shape: {real_final_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synth_labels: Counter({0: 3047, 1: 3030, 3: 3023, 2: 2900})\n",
      "real_labels: Counter({0: 2560, 1: 1792, 2: 717, 3: 52})\n",
      "real_final_labels: Counter({0: 640, 1: 448, 2: 179, 3: 12})\n"
     ]
    }
   ],
   "source": [
    "# print labels distribution\n",
    "print(f'synth_labels: {Counter(synth_labels)}')\n",
    "print(f'real_labels: {Counter(real_labels)}')\n",
    "print(f'real_final_labels: {Counter(real_final_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary classification\n",
    "synth_labels = np.clip(synth_labels, 0, 1)\n",
    "real_labels = np.clip(real_labels, 0, 1)\n",
    "real_final_labels = np.clip(real_final_labels, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synth_labels: Counter({1: 8953, 0: 3047})\n",
      "real_labels: Counter({1: 2561, 0: 2560})\n",
      "real_final_labels: Counter({0: 640, 1: 639})\n"
     ]
    }
   ],
   "source": [
    "# print labels distribution after binary classification\n",
    "print(f'synth_labels: {Counter(synth_labels)}')\n",
    "print(f'real_labels: {Counter(real_labels)}')\n",
    "print(f'real_final_labels: {Counter(real_final_labels)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "synth_train_img, synth_test_img, synth_train_label, synth_test_label = train_test_split(\n",
    "    synth_images, synth_labels, test_size=0.20, random_state=42,\n",
    ")\n",
    "real_train_img, real_test_img, real_train_label, real_test_label = train_test_split(\n",
    "    real_images, real_labels, test_size=0.20, random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transformation\n",
    "transform = transforms.Compose([\n",
    "    Unsqueeze(axis=-1),\n",
    "    Repeat(n_channel=3, axis=-1),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make datasets\n",
    "\n",
    "# synthetic\n",
    "synth_train_dataset = MRIDataset(\n",
    "    images=synth_train_img,\n",
    "    labels=synth_train_label,\n",
    "    transform=transform,\n",
    ")\n",
    "synth_test_dataset = MRIDataset(\n",
    "    images=synth_test_img,\n",
    "    labels=synth_test_label,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# real\n",
    "real_train_dataset = MRIDataset(\n",
    "    images=real_train_img,\n",
    "    labels=real_train_label,\n",
    "    transform=transform,\n",
    ")\n",
    "real_test_dataset = MRIDataset(\n",
    "    images=real_test_img,\n",
    "    labels=real_test_label,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# real_final\n",
    "real_final_dataset = MRIDataset(\n",
    "    images=real_final_images,\n",
    "    labels=real_labels,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataloaders\n",
    "\n",
    "# synthetic\n",
    "synth_train_loader = DataLoader(\n",
    "    synth_train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "synth_test_loader = DataLoader(\n",
    "    synth_test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# real\n",
    "real_train_loader = DataLoader(\n",
    "    real_train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "real_test_loader = DataLoader(\n",
    "    real_test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# real_final\n",
    "real_final_loader = DataLoader(\n",
    "    real_final_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### synthetic vs synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvDropoutNet(in_channels=3, n_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of params: 172434\n"
     ]
    }
   ],
   "source": [
    "print(f'num of params: {sum(p.numel() for p in model.parameters())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    trainloader=synth_train_loader,\n",
    "    valloader=synth_test_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    n_epochs=10,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), 'models/synthetic_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### real vs real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_resnet18(num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of params: 11177538\n"
     ]
    }
   ],
   "source": [
    "print(f'num of params: {sum(p.numel() for p in model.parameters())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    trainloader=real_train_loader,\n",
    "    valloader=real_test_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    n_epochs=10,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), 'models/real_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### synthetic vs real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_resnet18(num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of params: 11177538\n"
     ]
    }
   ],
   "source": [
    "print(f'num of params: {sum(p.numel() for p in model.parameters())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/5]\n",
      "\n",
      "train accuracy: 0.9540\n",
      "\n",
      "train metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91      2434\n",
      "           1       0.96      0.97      0.97      7166\n",
      "\n",
      "    accuracy                           0.95      9600\n",
      "   macro avg       0.94      0.93      0.94      9600\n",
      "weighted avg       0.95      0.95      0.95      9600\n",
      "\n",
      "\n",
      "val accuracy: 0.6626\n",
      "\n",
      "val metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.69      0.67      2061\n",
      "           1       0.67      0.64      0.65      2035\n",
      "\n",
      "    accuracy                           0.66      4096\n",
      "   macro avg       0.66      0.66      0.66      4096\n",
      "weighted avg       0.66      0.66      0.66      4096\n",
      "\n",
      "\n",
      "=====================================================\n",
      "\n",
      "epoch [2/5]\n",
      "\n",
      "train accuracy: 0.9871\n",
      "\n",
      "train metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      2434\n",
      "           1       0.99      0.99      0.99      7166\n",
      "\n",
      "    accuracy                           0.99      9600\n",
      "   macro avg       0.98      0.98      0.98      9600\n",
      "weighted avg       0.99      0.99      0.99      9600\n",
      "\n",
      "\n",
      "val accuracy: 0.5981\n",
      "\n",
      "val metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.78      0.66      2061\n",
      "           1       0.65      0.41      0.50      2035\n",
      "\n",
      "    accuracy                           0.60      4096\n",
      "   macro avg       0.61      0.60      0.58      4096\n",
      "weighted avg       0.61      0.60      0.58      4096\n",
      "\n",
      "\n",
      "=====================================================\n",
      "\n",
      "epoch [3/5]\n",
      "\n",
      "train accuracy: 0.9902\n",
      "\n",
      "train metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2434\n",
      "           1       0.99      0.99      0.99      7166\n",
      "\n",
      "    accuracy                           0.99      9600\n",
      "   macro avg       0.99      0.99      0.99      9600\n",
      "weighted avg       0.99      0.99      0.99      9600\n",
      "\n",
      "\n",
      "val accuracy: 0.5613\n",
      "\n",
      "val metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.13      0.23      2061\n",
      "           1       0.53      0.99      0.69      2035\n",
      "\n",
      "    accuracy                           0.56      4096\n",
      "   macro avg       0.75      0.56      0.46      4096\n",
      "weighted avg       0.75      0.56      0.46      4096\n",
      "\n",
      "\n",
      "=====================================================\n",
      "\n",
      "epoch [4/5]\n",
      "\n",
      "train accuracy: 0.9928\n",
      "\n",
      "train metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      2434\n",
      "           1       0.99      1.00      1.00      7166\n",
      "\n",
      "    accuracy                           0.99      9600\n",
      "   macro avg       0.99      0.99      0.99      9600\n",
      "weighted avg       0.99      0.99      0.99      9600\n",
      "\n",
      "\n",
      "val accuracy: 0.6570\n",
      "\n",
      "val metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66      2061\n",
      "           1       0.66      0.65      0.65      2035\n",
      "\n",
      "    accuracy                           0.66      4096\n",
      "   macro avg       0.66      0.66      0.66      4096\n",
      "weighted avg       0.66      0.66      0.66      4096\n",
      "\n",
      "\n",
      "=====================================================\n",
      "\n",
      "epoch [5/5]\n",
      "\n",
      "train accuracy: 0.9917\n",
      "\n",
      "train metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      2434\n",
      "           1       0.99      1.00      0.99      7166\n",
      "\n",
      "    accuracy                           0.99      9600\n",
      "   macro avg       0.99      0.99      0.99      9600\n",
      "weighted avg       0.99      0.99      0.99      9600\n",
      "\n",
      "\n",
      "val accuracy: 0.6484\n",
      "\n",
      "val metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.65      2061\n",
      "           1       0.65      0.64      0.64      2035\n",
      "\n",
      "    accuracy                           0.65      4096\n",
      "   macro avg       0.65      0.65      0.65      4096\n",
      "weighted avg       0.65      0.65      0.65      4096\n",
      "\n",
      "\n",
      "=====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    trainloader=synth_train_loader,\n",
    "    valloader=real_train_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    n_epochs=5,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = validate_epoch(\n",
    "    model=model,\n",
    "    dataloader=real_final_loader,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    ")\n",
    "accuracy, report = metrics_callback(metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.4910\n",
      "\n",
      "metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.18      0.27       663\n",
      "           1       0.48      0.82      0.61       616\n",
      "\n",
      "    accuracy                           0.49      1279\n",
      "   macro avg       0.50      0.50      0.44      1279\n",
      "weighted avg       0.51      0.49      0.43      1279\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# final metrics\n",
    "print(f'accuracy: {accuracy:.4f}\\n')\n",
    "print(f'metrics:\\n{report}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adversarial validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concal all data (synthetic: 0, real: 1)\n",
    "all_images = np.concatenate([synth_images, real_images])\n",
    "all_labels = np.concatenate([np.zeros(len(synth_images)), np.ones(len(real_images))]).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_val_dataset = MRIDataset(\n",
    "    images=all_images,\n",
    "    labels=all_labels,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(len(adv_val_dataset) * 0.8)\n",
    "val_len = len(adv_val_dataset) - train_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_val_train_dataset, adv_val_test_dataset = random_split(\n",
    "    dataset=adv_val_dataset,\n",
    "    lengths=[train_len, val_len],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_val_train_loader = DataLoader(\n",
    "    adv_val_train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "adv_val_test_loader = DataLoader(\n",
    "    adv_val_test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvDropoutNet(in_channels=3, n_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of params: 172434\n"
     ]
    }
   ],
   "source": [
    "print(f'num of params: {sum(p.numel() for p in model.parameters())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    trainloader=adv_val_train_loader,\n",
    "    valloader=adv_val_test_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    n_epochs=2,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter bad images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_dataset = MRIDataset(\n",
    "    images=synth_images,\n",
    "    labels=synth_labels,\n",
    "    transform=transform,\n",
    ")\n",
    "real_dataset = MRIDataset(\n",
    "    images=real_images,\n",
    "    labels=real_labels,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image scores\n",
    "scores = []\n",
    "for img, _ in synth_dataset:\n",
    "    with torch.no_grad():\n",
    "        img = img.unsqueeze(0).to(device)\n",
    "        score = torch.softmax(model(img), dim=1)[0][1].item()\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most synthetic image probability: 1.4090519029341664e-10\n",
      "least synthetic image probability: 0.5821159482002258\n"
     ]
    }
   ],
   "source": [
    "print(f'most synthetic image probability: {np.min(scores)}')\n",
    "print(f'least synthetic image probability: {np.max(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter bad images\n",
    "indices = np.argsort(scores)[-6000:]\n",
    "\n",
    "good_synth_images = synth_images[indices]\n",
    "good_synth_labels = synth_labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good_synth_labels: Counter({1: 4031, 0: 1969})\n"
     ]
    }
   ],
   "source": [
    "print(f'good_synth_labels: {Counter(good_synth_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_synth_dataset = MRIDataset(\n",
    "    images=good_synth_images,\n",
    "    labels=good_synth_labels,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_synth_loader = DataLoader(\n",
    "    good_synth_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### synthetic vs real v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_resnet18(num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of params: 11177538\n"
     ]
    }
   ],
   "source": [
    "print(f'num of params: {sum(p.numel() for p in model.parameters())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/5]\n",
      "\n",
      "train accuracy: 0.9410\n",
      "\n",
      "train metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      1969\n",
      "           1       0.95      0.97      0.96      4031\n",
      "\n",
      "    accuracy                           0.94      6000\n",
      "   macro avg       0.94      0.93      0.93      6000\n",
      "weighted avg       0.94      0.94      0.94      6000\n",
      "\n",
      "\n",
      "val accuracy: 0.6375\n",
      "\n",
      "val metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.70      0.66      2061\n",
      "           1       0.65      0.58      0.61      2035\n",
      "\n",
      "    accuracy                           0.64      4096\n",
      "   macro avg       0.64      0.64      0.64      4096\n",
      "weighted avg       0.64      0.64      0.64      4096\n",
      "\n",
      "\n",
      "=====================================================\n",
      "\n",
      "epoch [2/5]\n",
      "\n",
      "train accuracy: 0.9743\n",
      "\n",
      "train metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1969\n",
      "           1       0.98      0.98      0.98      4031\n",
      "\n",
      "    accuracy                           0.97      6000\n",
      "   macro avg       0.97      0.97      0.97      6000\n",
      "weighted avg       0.97      0.97      0.97      6000\n",
      "\n",
      "\n",
      "val accuracy: 0.6260\n",
      "\n",
      "val metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.71      0.66      2061\n",
      "           1       0.65      0.54      0.59      2035\n",
      "\n",
      "    accuracy                           0.63      4096\n",
      "   macro avg       0.63      0.63      0.62      4096\n",
      "weighted avg       0.63      0.63      0.62      4096\n",
      "\n",
      "\n",
      "=====================================================\n",
      "\n",
      "epoch [3/5]\n",
      "\n",
      "train accuracy: 0.9877\n",
      "\n",
      "train metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1969\n",
      "           1       0.99      0.99      0.99      4031\n",
      "\n",
      "    accuracy                           0.99      6000\n",
      "   macro avg       0.99      0.99      0.99      6000\n",
      "weighted avg       0.99      0.99      0.99      6000\n",
      "\n",
      "\n",
      "val accuracy: 0.5698\n",
      "\n",
      "val metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.82      0.66      2061\n",
      "           1       0.64      0.31      0.42      2035\n",
      "\n",
      "    accuracy                           0.57      4096\n",
      "   macro avg       0.59      0.57      0.54      4096\n",
      "weighted avg       0.59      0.57      0.54      4096\n",
      "\n",
      "\n",
      "=====================================================\n",
      "\n",
      "epoch [4/5]\n",
      "\n",
      "train accuracy: 0.9828\n",
      "\n",
      "train metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1969\n",
      "           1       0.99      0.99      0.99      4031\n",
      "\n",
      "    accuracy                           0.98      6000\n",
      "   macro avg       0.98      0.98      0.98      6000\n",
      "weighted avg       0.98      0.98      0.98      6000\n",
      "\n",
      "\n",
      "val accuracy: 0.6333\n",
      "\n",
      "val metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.34      0.48      2061\n",
      "           1       0.58      0.93      0.72      2035\n",
      "\n",
      "    accuracy                           0.63      4096\n",
      "   macro avg       0.71      0.64      0.60      4096\n",
      "weighted avg       0.71      0.63      0.60      4096\n",
      "\n",
      "\n",
      "=====================================================\n",
      "\n",
      "epoch [5/5]\n",
      "\n",
      "train accuracy: 0.9897\n",
      "\n",
      "train metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1969\n",
      "           1       0.99      0.99      0.99      4031\n",
      "\n",
      "    accuracy                           0.99      6000\n",
      "   macro avg       0.99      0.99      0.99      6000\n",
      "weighted avg       0.99      0.99      0.99      6000\n",
      "\n",
      "\n",
      "val accuracy: 0.6274\n",
      "\n",
      "val metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.71      0.66      2061\n",
      "           1       0.65      0.54      0.59      2035\n",
      "\n",
      "    accuracy                           0.63      4096\n",
      "   macro avg       0.63      0.63      0.62      4096\n",
      "weighted avg       0.63      0.63      0.62      4096\n",
      "\n",
      "\n",
      "=====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    trainloader=good_synth_loader,\n",
    "    valloader=real_train_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    n_epochs=5,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = validate_epoch(\n",
    "    model=model,\n",
    "    dataloader=real_final_loader,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    ")\n",
    "accuracy, report = metrics_callback(metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.4988\n",
      "\n",
      "metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.56      0.54       663\n",
      "           1       0.48      0.44      0.46       616\n",
      "\n",
      "    accuracy                           0.50      1279\n",
      "   macro avg       0.50      0.50      0.50      1279\n",
      "weighted avg       0.50      0.50      0.50      1279\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# final metrics\n",
    "print(f'accuracy: {accuracy:.4f}\\n')\n",
    "print(f'metrics:\\n{report}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
